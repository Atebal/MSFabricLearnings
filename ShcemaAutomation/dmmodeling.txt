DimAccountSchema=StructType([
StructField(AccountKey,IntegerType(),nullable=False),
StructField(ParentAccountKey,IntegerType(),nullable=True),
StructField(AccountCodeAlternateKey,IntegerType(),nullable=True),
StructField(ParentAccountCodeAlternateKey,IntegerType(),nullable=True),
StructField(AccountDescription,StringType(),nullable=True),
StructField(AccountType,StringType(),nullable=True),
StructField(Operator,StringType(),nullable=True),
StructField(CustomMembers,StringType(),nullable=True),
StructField(ValueType,StringType(),nullable=True),
StructField(CustomMemberOptions,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimAccountSchema).format("csv").load("Files/AdventureWorksDW/DimAccount.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimAccount")


DimCurrencySchema=StructType([
StructField(CurrencyKey,IntegerType(),nullable=False),
StructField(CurrencyAlternateKey,StringType(),nullable=False),
StructField(CurrencyName,StringType(),nullable=False),
])

df = spark.read.option("sep", "|").schema(DimCurrencySchema).format("csv").load("Files/AdventureWorksDW/DimCurrency.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimCurrency")


DimCustomerSchema=StructType([
StructField(CustomerKey,IntegerType(),nullable=False),
StructField(GeographyKey,IntegerType(),nullable=True),
StructField(CustomerAlternateKey,StringType(),nullable=False),
StructField(Title,StringType(),nullable=True),
StructField(FirstName,StringType(),nullable=True),
StructField(MiddleName,StringType(),nullable=True),
StructField(LastName,StringType(),nullable=True),
StructField(NameStyle,IntegerType(),nullable=True),
StructField(BirthDate,DateType(),nullable=True),
StructField(MaritalStatus,StringType(),nullable=True),
StructField(Suffix,StringType(),nullable=True),
StructField(Gender,StringType(),nullable=True),
StructField(EmailAddress,StringType(),nullable=True),
StructField(YearlyIncome,FloatType(),nullable=True),
StructField(TotalChildren,IntegerType(),nullable=True),
StructField(NumberChildrenAtHome,IntegerType(),nullable=True),
StructField(EnglishEducation,StringType(),nullable=True),
StructField(SpanishEducation,StringType(),nullable=True),
StructField(FrenchEducation,StringType(),nullable=True),
StructField(EnglishOccupation,StringType(),nullable=True),
StructField(SpanishOccupation,StringType(),nullable=True),
StructField(FrenchOccupation,StringType(),nullable=True),
StructField(HouseOwnerFlag,StringType(),nullable=True),
StructField(NumberCarsOwned,IntegerType(),nullable=True),
StructField(AddressLine1,StringType(),nullable=True),
StructField(AddressLine2,StringType(),nullable=True),
StructField(Phone,StringType(),nullable=True),
StructField(DateFirstPurchase,DateType(),nullable=True),
StructField(CommuteDistance,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimCustomerSchema).format("csv").load("Files/AdventureWorksDW/DimCustomer.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimCustomer")


DimDateSchema=StructType([
StructField(DateKey,IntegerType(),nullable=False),
StructField(FullDateAlternateKey,DateType(),nullable=False),
StructField(DayNumberOfWeek,IntegerType(),nullable=False),
StructField(EnglishDayNameOfWeek,StringType(),nullable=False),
StructField(SpanishDayNameOfWeek,StringType(),nullable=False),
StructField(FrenchDayNameOfWeek,StringType(),nullable=False),
StructField(DayNumberOfMonth,IntegerType(),nullable=False),
StructField(DayNumberOfYear,StringType(),nullable=False),
StructField(WeekNumberOfYear,IntegerType(),nullable=False),
StructField(EnglishMonthName,StringType(),nullable=False),
StructField(SpanishMonthName,StringType(),nullable=False),
StructField(FrenchMonthName,StringType(),nullable=False),
StructField(MonthNumberOfYear,IntegerType(),nullable=False),
StructField(CalendarQuarter,IntegerType(),nullable=False),
StructField(CalendarYear,StringType(),nullable=False),
StructField(CalendarSemester,IntegerType(),nullable=False),
StructField(FiscalQuarter,IntegerType(),nullable=False),
StructField(FiscalYear,StringType(),nullable=False),
StructField(FiscalSemester,IntegerType(),nullable=False),
])

df = spark.read.option("sep", "|").schema(DimDateSchema).format("csv").load("Files/AdventureWorksDW/DimDate.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimDate")


DimDepartmentGroupSchema=StructType([
StructField(DepartmentGroupKey,IntegerType(),nullable=False),
StructField(ParentDepartmentGroupKey,IntegerType(),nullable=True),
StructField(DepartmentGroupName,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimDepartmentGroupSchema).format("csv").load("Files/AdventureWorksDW/DimDepartmentGroup.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimDepartmentGroup")


DimEmployeeSchema=StructType([
StructField(EmployeeKey,IntegerType(),nullable=False),
StructField(ParentEmployeeKey,IntegerType(),nullable=True),
StructField(EmployeeNationalIDAlternateKey,StringType(),nullable=True),
StructField(ParentEmployeeNationalIDAlternateKey,StringType(),nullable=True),
StructField(SalesTerritoryKey,IntegerType(),nullable=True),
StructField(FirstName,StringType(),nullable=False),
StructField(LastName,StringType(),nullable=False),
StructField(MiddleName,StringType(),nullable=True),
StructField(NameStyle,IntegerType(),nullable=False),
StructField(Title,StringType(),nullable=True),
StructField(HireDate,DateType(),nullable=True),
StructField(BirthDate,DateType(),nullable=True),
StructField(LoginID,StringType(),nullable=True),
StructField(EmailAddress,StringType(),nullable=True),
StructField(Phone,StringType(),nullable=True),
StructField(MaritalStatus,StringType(),nullable=True),
StructField(EmergencyContactName,StringType(),nullable=True),
StructField(EmergencyContactPhone,StringType(),nullable=True),
StructField(SalariedFlag,IntegerType(),nullable=True),
StructField(Gender,StringType(),nullable=True),
StructField(PayFrequency,IntegerType(),nullable=True),
StructField(BaseRate,FloatType(),nullable=True),
StructField(VacationHours,StringType(),nullable=True),
StructField(SickLeaveHours,StringType(),nullable=True),
StructField(CurrentFlag,IntegerType(),nullable=False),
StructField(SalesPersonFlag,IntegerType(),nullable=False),
StructField(DepartmentName,StringType(),nullable=True),
StructField(StartDate,DateType(),nullable=True),
StructField(EndDate,DateType(),nullable=True),
StructField(Status,StringType(),nullable=True),
StructField(EmployeePhoto,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimEmployeeSchema).format("csv").load("Files/AdventureWorksDW/DimEmployee.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimEmployee")


DimGeographySchema=StructType([
StructField(GeographyKey,IntegerType(),nullable=False),
StructField(City,StringType(),nullable=True),
StructField(StateProvinceCode,StringType(),nullable=True),
StructField(StateProvinceName,StringType(),nullable=True),
StructField(CountryRegionCode,StringType(),nullable=True),
StructField(EnglishCountryRegionName,StringType(),nullable=True),
StructField(SpanishCountryRegionName,StringType(),nullable=True),
StructField(FrenchCountryRegionName,StringType(),nullable=True),
StructField(PostalCode,StringType(),nullable=True),
StructField(SalesTerritoryKey,IntegerType(),nullable=True),
StructField(IpAddressLocator,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimGeographySchema).format("csv").load("Files/AdventureWorksDW/DimGeography.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimGeography")


DimOrganizationSchema=StructType([
StructField(OrganizationKey,IntegerType(),nullable=False),
StructField(ParentOrganizationKey,IntegerType(),nullable=True),
StructField(PercentageOfOwnership,StringType(),nullable=True),
StructField(OrganizationName,StringType(),nullable=True),
StructField(CurrencyKey,IntegerType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimOrganizationSchema).format("csv").load("Files/AdventureWorksDW/DimOrganization.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimOrganization")


DimProductSchema=StructType([
StructField(ProductKey,IntegerType(),nullable=False),
StructField(ProductAlternateKey,StringType(),nullable=True),
StructField(ProductSubcategoryKey,IntegerType(),nullable=True),
StructField(WeightUnitMeasureCode,StringType(),nullable=True),
StructField(SizeUnitMeasureCode,StringType(),nullable=True),
StructField(EnglishProductName,StringType(),nullable=False),
StructField(SpanishProductName,StringType(),nullable=False),
StructField(FrenchProductName,StringType(),nullable=False),
StructField(StandardCost,FloatType(),nullable=True),
StructField(FinishedGoodsFlag,IntegerType(),nullable=False),
StructField(Color,StringType(),nullable=False),
StructField(SafetyStockLevel,StringType(),nullable=True),
StructField(ReorderPoint,StringType(),nullable=True),
StructField(ListPrice,FloatType(),nullable=True),
StructField(Size,StringType(),nullable=True),
StructField(SizeRange,StringType(),nullable=True),
StructField(Weight,FloatType(),nullable=True),
StructField(DaysToManufacture,IntegerType(),nullable=True),
StructField(ProductLine,StringType(),nullable=True),
StructField(DealerPrice,FloatType(),nullable=True),
StructField(Class,StringType(),nullable=True),
StructField(Style,StringType(),nullable=True),
StructField(ModelName,StringType(),nullable=True),
StructField(LargePhoto,StringType(),nullable=True),
StructField(EnglishDescription,StringType(),nullable=True),
StructField(FrenchDescription,StringType(),nullable=True),
StructField(ChineseDescription,StringType(),nullable=True),
StructField(ArabicDescription,StringType(),nullable=True),
StructField(HebrewDescription,StringType(),nullable=True),
StructField(ThaiDescription,StringType(),nullable=True),
StructField(GermanDescription,StringType(),nullable=True),
StructField(JapaneseDescription,StringType(),nullable=True),
StructField(TurkishDescription,StringType(),nullable=True),
StructField(StartDate,DateType(),nullable=True),
StructField(EndDate,DateType(),nullable=True),
StructField(Status,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimProductSchema).format("csv").load("Files/AdventureWorksDW/DimProduct.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimProduct")


DimProductCategorySchema=StructType([
StructField(ProductCategoryKey,IntegerType(),nullable=False),
StructField(ProductCategoryAlternateKey,IntegerType(),nullable=True),
StructField(EnglishProductCategoryName,StringType(),nullable=False),
StructField(SpanishProductCategoryName,StringType(),nullable=False),
StructField(FrenchProductCategoryName,StringType(),nullable=False),
])

df = spark.read.option("sep", "|").schema(DimProductCategorySchema).format("csv").load("Files/AdventureWorksDW/DimProductCategory.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimProductCategory")


DimProductSubcategorySchema=StructType([
StructField(ProductSubcategoryKey,IntegerType(),nullable=False),
StructField(ProductSubcategoryAlternateKey,IntegerType(),nullable=True),
StructField(EnglishProductSubcategoryName,StringType(),nullable=False),
StructField(SpanishProductSubcategoryName,StringType(),nullable=False),
StructField(FrenchProductSubcategoryName,StringType(),nullable=False),
StructField(ProductCategoryKey,IntegerType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimProductSubcategorySchema).format("csv").load("Files/AdventureWorksDW/DimProductSubcategory.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimProductSubcategory")


DimPromotionSchema=StructType([
StructField(PromotionKey,IntegerType(),nullable=False),
StructField(PromotionAlternateKey,IntegerType(),nullable=True),
StructField(EnglishPromotionName,StringType(),nullable=True),
StructField(SpanishPromotionName,StringType(),nullable=True),
StructField(FrenchPromotionName,StringType(),nullable=True),
StructField(DiscountPct,FloatType(),nullable=True),
StructField(EnglishPromotionType,StringType(),nullable=True),
StructField(SpanishPromotionType,StringType(),nullable=True),
StructField(FrenchPromotionType,StringType(),nullable=True),
StructField(EnglishPromotionCategory,StringType(),nullable=True),
StructField(SpanishPromotionCategory,StringType(),nullable=True),
StructField(FrenchPromotionCategory,StringType(),nullable=True),
StructField(StartDate,DateType(),nullable=False),
StructField(EndDate,DateType(),nullable=True),
StructField(MinQty,IntegerType(),nullable=True),
StructField(MaxQty,IntegerType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimPromotionSchema).format("csv").load("Files/AdventureWorksDW/DimPromotion.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimPromotion")


DimResellerSchema=StructType([
StructField(ResellerKey,IntegerType(),nullable=False),
StructField(GeographyKey,IntegerType(),nullable=True),
StructField(ResellerAlternateKey,StringType(),nullable=True),
StructField(Phone,StringType(),nullable=True),
StructField(BusinessType,StringType(),nullable=False),
StructField(ResellerName,StringType(),nullable=False),
StructField(NumberEmployees,IntegerType(),nullable=True),
StructField(OrderFrequency,StringType(),nullable=True),
StructField(OrderMonth,IntegerType(),nullable=True),
StructField(FirstOrderYear,IntegerType(),nullable=True),
StructField(LastOrderYear,IntegerType(),nullable=True),
StructField(ProductLine,StringType(),nullable=True),
StructField(AddressLine1,StringType(),nullable=True),
StructField(AddressLine2,StringType(),nullable=True),
StructField(AnnualSales,FloatType(),nullable=True),
StructField(BankName,StringType(),nullable=True),
StructField(MinPaymentType,IntegerType(),nullable=True),
StructField(MinPaymentAmount,FloatType(),nullable=True),
StructField(AnnualRevenue,FloatType(),nullable=True),
StructField(YearOpened,IntegerType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimResellerSchema).format("csv").load("Files/AdventureWorksDW/DimReseller.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimReseller")


DimSalesReasonSchema=StructType([
StructField(SalesReasonKey,IntegerType(),nullable=False),
StructField(SalesReasonAlternateKey,IntegerType(),nullable=False),
StructField(SalesReasonName,StringType(),nullable=False),
StructField(SalesReasonReasonType,StringType(),nullable=False),
])

df = spark.read.option("sep", "|").schema(DimSalesReasonSchema).format("csv").load("Files/AdventureWorksDW/DimSalesReason.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimSalesReason")


DimSalesTerritorySchema=StructType([
StructField(SalesTerritoryKey,IntegerType(),nullable=False),
StructField(SalesTerritoryAlternateKey,IntegerType(),nullable=True),
StructField(SalesTerritoryRegion,StringType(),nullable=False),
StructField(SalesTerritoryCountry,StringType(),nullable=False),
StructField(SalesTerritoryGroup,StringType(),nullable=True),
StructField(SalesTerritoryImage,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimSalesTerritorySchema).format("csv").load("Files/AdventureWorksDW/DimSalesTerritory.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimSalesTerritory")


DimScenarioSchema=StructType([
StructField(ScenarioKey,IntegerType(),nullable=False),
StructField(ScenarioName,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(DimScenarioSchema).format("csv").load("Files/AdventureWorksDW/DimScenario.csv")
df.write.mode("overwrite").format("delta").save("Tables/DimScenario")


FactAdditionalInternationalProductDescriptionSchema=StructType([
StructField(ProductKey,IntegerType(),nullable=False),
StructField(CultureName,StringType(),nullable=False),
StructField(ProductDescription,StringType(),nullable=False),
])

df = spark.read.option("sep", "|").schema(FactAdditionalInternationalProductDescriptionSchema).format("csv").load("Files/AdventureWorksDW/FactAdditionalInternationalProductDescription.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactAdditionalInternationalProductDescription")


FactCallCenterSchema=StructType([
StructField(FactCallCenterID,IntegerType(),nullable=False),
StructField(DateKey,IntegerType(),nullable=False),
StructField(WageType,StringType(),nullable=False),
StructField(Shift,StringType(),nullable=False),
StructField(LevelOneOperators,StringType(),nullable=False),
StructField(LevelTwoOperators,StringType(),nullable=False),
StructField(TotalOperators,StringType(),nullable=False),
StructField(Calls,IntegerType(),nullable=False),
StructField(AutomaticResponses,IntegerType(),nullable=False),
StructField(Orders,IntegerType(),nullable=False),
StructField(IssuesRaised,StringType(),nullable=False),
StructField(AverageTimePerIssue,StringType(),nullable=False),
StructField(ServiceGrade,FloatType(),nullable=False),
StructField(Date,DateType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(FactCallCenterSchema).format("csv").load("Files/AdventureWorksDW/FactCallCenter.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactCallCenter")


FactCurrencyRateSchema=StructType([
StructField(CurrencyKey,IntegerType(),nullable=False),
StructField(DateKey,IntegerType(),nullable=False),
StructField(AverageRate,FloatType(),nullable=False),
StructField(EndOfDayRate,FloatType(),nullable=False),
StructField(Date,DateType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(FactCurrencyRateSchema).format("csv").load("Files/AdventureWorksDW/FactCurrencyRate.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactCurrencyRate")


FactFinanceSchema=StructType([
StructField(FinanceKey,IntegerType(),nullable=False),
StructField(DateKey,IntegerType(),nullable=False),
StructField(OrganizationKey,IntegerType(),nullable=False),
StructField(DepartmentGroupKey,IntegerType(),nullable=False),
StructField(ScenarioKey,IntegerType(),nullable=False),
StructField(AccountKey,IntegerType(),nullable=False),
StructField(Amount,FloatType(),nullable=False),
StructField(Date,DateType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(FactFinanceSchema).format("csv").load("Files/AdventureWorksDW/FactFinance.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactFinance")


FactInternetSalesSchema=StructType([
StructField(ProductKey,IntegerType(),nullable=False),
StructField(OrderDateKey,IntegerType(),nullable=False),
StructField(DueDateKey,IntegerType(),nullable=False),
StructField(ShipDateKey,IntegerType(),nullable=False),
StructField(CustomerKey,IntegerType(),nullable=False),
StructField(PromotionKey,IntegerType(),nullable=False),
StructField(CurrencyKey,IntegerType(),nullable=False),
StructField(SalesTerritoryKey,IntegerType(),nullable=False),
StructField(SalesOrderNumber,StringType(),nullable=False),
StructField(SalesOrderLineNumber,IntegerType(),nullable=False),
StructField(RevisionNumber,IntegerType(),nullable=False),
StructField(OrderQuantity,StringType(),nullable=False),
StructField(UnitPrice,FloatType(),nullable=False),
StructField(ExtendedAmount,FloatType(),nullable=False),
StructField(UnitPriceDiscountPct,FloatType(),nullable=False),
StructField(DiscountAmount,FloatType(),nullable=False),
StructField(ProductStandardCost,FloatType(),nullable=False),
StructField(TotalProductCost,FloatType(),nullable=False),
StructField(SalesAmount,FloatType(),nullable=False),
StructField(TaxAmt,FloatType(),nullable=False),
StructField(Freight,FloatType(),nullable=False),
StructField(CarrierTrackingNumber,StringType(),nullable=True),
StructField(CustomerPONumber,StringType(),nullable=True),
StructField(OrderDate,DateType(),nullable=True),
StructField(DueDate,DateType(),nullable=True),
StructField(ShipDate,DateType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(FactInternetSalesSchema).format("csv").load("Files/AdventureWorksDW/FactInternetSales.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactInternetSales")


FactInternetSalesReasonSchema=StructType([
StructField(SalesOrderNumber,StringType(),nullable=False),
StructField(SalesOrderLineNumber,IntegerType(),nullable=False),
StructField(SalesReasonKey,IntegerType(),nullable=False),
])

df = spark.read.option("sep", "|").schema(FactInternetSalesReasonSchema).format("csv").load("Files/AdventureWorksDW/FactInternetSalesReason.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactInternetSalesReason")


FactProductInventorySchema=StructType([
StructField(ProductKey,IntegerType(),nullable=False),
StructField(DateKey,IntegerType(),nullable=False),
StructField(MovementDate,DateType(),nullable=False),
StructField(UnitCost,FloatType(),nullable=False),
StructField(UnitsIn,IntegerType(),nullable=False),
StructField(UnitsOut,IntegerType(),nullable=False),
StructField(UnitsBalance,IntegerType(),nullable=False),
])

df = spark.read.option("sep", "|").schema(FactProductInventorySchema).format("csv").load("Files/AdventureWorksDW/FactProductInventory.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactProductInventory")


FactResellerSalesSchema=StructType([
StructField(ProductKey,IntegerType(),nullable=False),
StructField(OrderDateKey,IntegerType(),nullable=False),
StructField(DueDateKey,IntegerType(),nullable=False),
StructField(ShipDateKey,IntegerType(),nullable=False),
StructField(ResellerKey,IntegerType(),nullable=False),
StructField(EmployeeKey,IntegerType(),nullable=False),
StructField(PromotionKey,IntegerType(),nullable=False),
StructField(CurrencyKey,IntegerType(),nullable=False),
StructField(SalesTerritoryKey,IntegerType(),nullable=False),
StructField(SalesOrderNumber,StringType(),nullable=False),
StructField(SalesOrderLineNumber,IntegerType(),nullable=False),
StructField(RevisionNumber,IntegerType(),nullable=True),
StructField(OrderQuantity,StringType(),nullable=True),
StructField(UnitPrice,FloatType(),nullable=True),
StructField(ExtendedAmount,FloatType(),nullable=True),
StructField(UnitPriceDiscountPct,FloatType(),nullable=True),
StructField(DiscountAmount,FloatType(),nullable=True),
StructField(ProductStandardCost,FloatType(),nullable=True),
StructField(TotalProductCost,FloatType(),nullable=True),
StructField(SalesAmount,FloatType(),nullable=True),
StructField(TaxAmt,FloatType(),nullable=True),
StructField(Freight,FloatType(),nullable=True),
StructField(CarrierTrackingNumber,StringType(),nullable=True),
StructField(CustomerPONumber,StringType(),nullable=True),
StructField(OrderDate,DateType(),nullable=True),
StructField(DueDate,DateType(),nullable=True),
StructField(ShipDate,DateType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(FactResellerSalesSchema).format("csv").load("Files/AdventureWorksDW/FactResellerSales.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactResellerSales")


FactSalesQuotaSchema=StructType([
StructField(SalesQuotaKey,IntegerType(),nullable=False),
StructField(EmployeeKey,IntegerType(),nullable=False),
StructField(DateKey,IntegerType(),nullable=False),
StructField(CalendarYear,StringType(),nullable=False),
StructField(CalendarQuarter,IntegerType(),nullable=False),
StructField(SalesAmountQuota,FloatType(),nullable=False),
StructField(Date,DateType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(FactSalesQuotaSchema).format("csv").load("Files/AdventureWorksDW/FactSalesQuota.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactSalesQuota")


FactSurveyResponseSchema=StructType([
StructField(SurveyResponseKey,IntegerType(),nullable=False),
StructField(DateKey,IntegerType(),nullable=False),
StructField(CustomerKey,IntegerType(),nullable=False),
StructField(ProductCategoryKey,IntegerType(),nullable=False),
StructField(EnglishProductCategoryName,StringType(),nullable=False),
StructField(ProductSubcategoryKey,IntegerType(),nullable=False),
StructField(EnglishProductSubcategoryName,StringType(),nullable=False),
StructField(Date,DateType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(FactSurveyResponseSchema).format("csv").load("Files/AdventureWorksDW/FactSurveyResponse.csv")
df.write.mode("overwrite").format("delta").save("Tables/FactSurveyResponse")


NewFactCurrencyRateSchema=StructType([
StructField(AverageRate,StringType(),nullable=True),
StructField(CurrencyID,StringType(),nullable=True),
StructField(CurrencyDate,DateType(),nullable=True),
StructField(EndOfDayRate,StringType(),nullable=True),
StructField(CurrencyKey,IntegerType(),nullable=True),
StructField(DateKey,IntegerType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(NewFactCurrencyRateSchema).format("csv").load("Files/AdventureWorksDW/NewFactCurrencyRate.csv")
df.write.mode("overwrite").format("delta").save("Tables/NewFactCurrencyRate")


ProspectiveBuyerSchema=StructType([
StructField(ProspectiveBuyerKey,IntegerType(),nullable=False),
StructField(ProspectAlternateKey,StringType(),nullable=True),
StructField(FirstName,StringType(),nullable=True),
StructField(MiddleName,StringType(),nullable=True),
StructField(LastName,StringType(),nullable=True),
StructField(BirthDate,DateType(),nullable=True),
StructField(MaritalStatus,StringType(),nullable=True),
StructField(Gender,StringType(),nullable=True),
StructField(EmailAddress,StringType(),nullable=True),
StructField(YearlyIncome,FloatType(),nullable=True),
StructField(TotalChildren,IntegerType(),nullable=True),
StructField(NumberChildrenAtHome,IntegerType(),nullable=True),
StructField(Education,StringType(),nullable=True),
StructField(Occupation,StringType(),nullable=True),
StructField(HouseOwnerFlag,StringType(),nullable=True),
StructField(NumberCarsOwned,IntegerType(),nullable=True),
StructField(AddressLine1,StringType(),nullable=True),
StructField(AddressLine2,StringType(),nullable=True),
StructField(City,StringType(),nullable=True),
StructField(StateProvinceCode,StringType(),nullable=True),
StructField(PostalCode,StringType(),nullable=True),
StructField(Phone,StringType(),nullable=True),
StructField(Salutation,StringType(),nullable=True),
StructField(Unknown,IntegerType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(ProspectiveBuyerSchema).format("csv").load("Files/AdventureWorksDW/ProspectiveBuyer.csv")
df.write.mode("overwrite").format("delta").save("Tables/ProspectiveBuyer")


sysdiagramsSchema=StructType([
StructField(name,StringType(),nullable=False),
StructField(principal_id,IntegerType(),nullable=False),
StructField(diagram_id,IntegerType(),nullable=False),
StructField(version,IntegerType(),nullable=True),
StructField(definition,StringType(),nullable=True),
])

df = spark.read.option("sep", "|").schema(sysdiagramsSchema).format("csv").load("Files/AdventureWorksDW/sysdiagrams.csv")
df.write.mode("overwrite").format("delta").save("Tables/sysdiagrams")


